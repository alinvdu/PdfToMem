# ðŸ§  PdfToMem  
**Turn PDFs into structured, queryable memoryâ€”built for LLMs.**

Large Language Models struggle with memory. `PdfToMem` makes it effortless.  
By combining reasoning-powered ingestion, structured retrieval, and a multi-agent architecture, it transforms unstructured PDFs into rich memory representations.  

It exposes a powerful **MCP Server** to coordinate ingestion, reasoning, storage, and queryingâ€”using state-of-the-art tools like **LlamaIndex** and **LangGraph**.

---

## ðŸŽ¥ Video Walkthrough
![Video Icon](https://github.com/user-attachments/assets/d8e0adb1-c455-43e7-9b7a-b01d14581042)[Watch the video](https://example.com/video.mp4)

## ðŸ§  MCP Server â€” _Memory Control Plane_

The **MCP Server** is the brain of PdfToMem. It leverages tool-based reasoning to:

- ðŸ—ï¸ **Design ingestion pipelines**
- ðŸ§© **Choose the right memory representation**
- ðŸ“Š **Index and structure PDF content for retrieval**

Use tools like `determine_memory_architecture` to automatically infer the optimal memory structure using **LlamaIndex abstractions**:
- `VectorIndex`
- `QueryEngine`
- `LLMSelector`

---

## ðŸ› ï¸ Tool-Driven Parsing â€” Powered by LangGraph

`PdfToMem` employs modular **tools** to extract structured data from PDFs:

- ðŸ“„ **Text Extraction**
- ðŸ“Š **Table Detection**
- ðŸ§¾ **OCR for Scanned Docs**
- ðŸ–¼ï¸ **Image Extraction**
- ðŸ“¸ **PDF Screenshots**

These tools feed into the **multi-agent system**, enabling intelligent, context-aware processing.

---

## ðŸ¤– Multi-Agent Architecture

PdfToMem uses a **LangGraph-based orchestrator** to coordinate specialized agents. Each agent performs a distinct task:

- ðŸ•µï¸ **Extractor Agent** â€“ pulls raw content  
- ðŸ§  **Semantic Agent** â€“ applies embedding & understanding  
- âœ‚ï¸ **Segmenter Agent** â€“ splits content intelligently  
- ðŸ•¸ï¸ **Relationship Agent** â€“ builds semantic links

The orchestrator decides **when and how** to invoke these agents based on the content type and reasoning goals.

---

## ðŸ§­ Memory Planning â€” Reasoning Over Representation

Once the data is structured, a **planning model** (currently `o3-mini`) determines the **best memory format** using **LlamaIndex** components:

- ðŸ§± `SimpleSentenceIndex`  
- ðŸŒ `AutoMergingIndex`  
- ðŸ§® Custom tool-enhanced indices

This reasoning-driven approach ensures **optimal retrieval performance** tailored to the document.

---

## ðŸ’¾ Storage â€” Flexible, Dynamic, Queryable

Based on the selected memory representation, a FastAPI-powered **Storage Service** builds a tailored **query engine** for each PDF.

- ðŸ” Built-in search and retrieval
- ðŸ§  Vector and hybrid index support
- ðŸ§ª Modular for experimentation

The storage is designed to support **scalable memory systems** across domains.

---

## ðŸ–¥ï¸ MCP Client â€” Full Control with a Friendly UI

The **MCP Client** is a React-based interface for controlling the full lifecycle:

- âš™ï¸ Configure agents, tools, memory plans  
- ðŸ“‚ Upload and ingest PDFs  
- ðŸ”Ž Preview structured chunks  
- ðŸ§ª Query memory and view responses  

Everything is interactive, inspectable, and customizable.

---

## ðŸš€ Why PdfToMem?

- âœ… **LLM-optimized ingestion & memory**  
- ðŸ§© **Modular tools & agents**  
- ðŸ§  **Reasoning-based memory planning**  
- ðŸ’¬ **Queryable representations via LlamaIndex**  
- ðŸŒ **UI + API for full pipeline control**

---

> ðŸ› ï¸ _Contributions welcome! Help us build the future of intelligent memory systems._  
> ðŸ”— [MIT License](./LICENSE)
